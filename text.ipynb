{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import omegaconf, torch\n",
    "\n",
    "from src import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(opt, model, optimizer):\n",
    "    start_time = time.time()\n",
    "    train_loader = utils.get_data(opt, \"train\")\n",
    "    num_steps_per_epoch = len(train_loader)\n",
    "\n",
    "    for epoch in range(opt.training.epochs):\n",
    "        train_results = defaultdict(float)\n",
    "        optimizer = utils.update_learning_rate(optimizer, opt, epoch)\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = utils.preprocess_inputs(opt, inputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            scalar_outputs = model(inputs, labels)\n",
    "            scalar_outputs[\"Loss\"].backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            train_results = utils.log_results(\n",
    "                train_results, scalar_outputs, num_steps_per_epoch\n",
    "            )\n",
    "\n",
    "        utils.print_results(\"train\", time.time() - start_time, train_results, epoch)\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Validate.\n",
    "        if epoch % opt.training.val_idx == 0 and opt.training.val_idx != -1:\n",
    "            validate_or_test(opt, model, \"val\", epoch=epoch)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def validate_or_test(opt, model, partition, epoch=None):\n",
    "    test_time = time.time()\n",
    "    test_results = defaultdict(float)\n",
    "\n",
    "    data_loader = utils.get_data(opt, partition)\n",
    "    num_steps_per_epoch = len(data_loader)\n",
    "\n",
    "    model.eval()\n",
    "    print(partition)\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = utils.preprocess_inputs(opt, inputs, labels)\n",
    "\n",
    "            scalar_outputs = model.forward_downstream_classification_model(\n",
    "                inputs, labels\n",
    "            )\n",
    "            test_results = utils.log_results(\n",
    "                test_results, scalar_outputs, num_steps_per_epoch\n",
    "            )\n",
    "\n",
    "    utils.print_results(partition, time.time() - test_time, test_results, epoch=epoch)\n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 42\n",
      "device: cpu\n",
      "input:\n",
      "  path: datasets\n",
      "  batch_size: 128\n",
      "  dataset: shakespeare\n",
      "  mnist:\n",
      "    encode_label: false\n",
      "  shakespeare:\n",
      "    sample_len: 64\n",
      "    num_classes: 65\n",
      "model:\n",
      "  peer_normalization: 0\n",
      "  momentum: 0.9\n",
      "  hidden_dim: 256\n",
      "  num_layers: 4\n",
      "training:\n",
      "  epochs: 1\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0003\n",
      "  momentum: 0.9\n",
      "  downstream_learning_rate: 0.01\n",
      "  downstream_weight_decay: 0.003\n",
      "  val_idx: -1\n",
      "  final_test: false\n",
      "hydra:\n",
      "  run:\n",
      "    dir: logs\n",
      "\n",
      "FF_model(\n",
      "  (model): ModuleList(\n",
      "    (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "    (1-3): 3 x Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (ff_loss): BCEWithLogitsLoss()\n",
      "  (linear_classifier): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=65, bias=False)\n",
      "  )\n",
      "  (classification_loss): CrossEntropyLoss()\n",
      ") \n",
      "\n",
      "Loading model...\n"
     ]
    }
   ],
   "source": [
    "cfg = omegaconf.OmegaConf.load(\"config.yaml\")\n",
    "opt = utils.parse_args(cfg)\n",
    "\n",
    "model, optimizer = utils.get_model_and_optimizer(opt)\n",
    "model_file = \"text_model.pt\"\n",
    "# If model exists, load it. Else, train it.\n",
    "if os.path.isfile(model_file):\n",
    "# if False:\n",
    "    print(\"Loading model...\")\n",
    "    state_dict = torch.load(model_file)\n",
    "    model.load_state_dict(state_dict)\n",
    "else:\n",
    "    print(\"Training model...\")\n",
    "    model = train(opt, model, optimizer)\n",
    "    torch.save(model.state_dict(), model_file)    \n",
    "\n",
    "# print(\"Testing model...\")\n",
    "# validate_or_test(opt, model, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'itos'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m tokens \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor([train_loader\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mstoi[x] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m context])\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mto(opt\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     37\u001b[0m generated \u001b[39m=\u001b[39m generate(model, tokens)\n\u001b[0;32m---> 38\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([train_loader\u001b[39m.\u001b[39;49mitos[x\u001b[39m.\u001b[39;49mitem()] \u001b[39mfor\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m generated]))\n",
      "Cell \u001b[0;32mIn[4], line 38\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     36\u001b[0m tokens \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor([train_loader\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mstoi[x] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m context])\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mto(opt\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     37\u001b[0m generated \u001b[39m=\u001b[39m generate(model, tokens)\n\u001b[0;32m---> 38\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([train_loader\u001b[39m.\u001b[39;49mitos[x\u001b[39m.\u001b[39mitem()] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m generated]))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'itos'"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate(self, idx, max_new_tokens=100, temperature=0.2, top_k=None):\n",
    "    \"\"\"\n",
    "    Take a conditioning sequence of indices idx (LongTensor of shape (b,t)) and complete\n",
    "    the sequence max_new_tokens times, feeding the predictions back into the model each time.\n",
    "    Most likely you'll want to make sure to be in model.eval() mode of operation for this.\n",
    "    \"\"\"\n",
    "    for _ in range(max_new_tokens):\n",
    "        # if the sequence context is growing too long we must crop it at block_size\n",
    "        sample_len = self.opt.input.shakespeare.sample_len\n",
    "        idx_cond = idx if idx.size(1) <= sample_len else idx[:, -sample_len:]\n",
    "        # forward the model to get the logits for the index in the sequence\n",
    "        logits = self({'neutral': idx_cond})[\"logits\"]\n",
    "        # pluck the logits at the final step and scale by desired temperature\n",
    "        logits = logits / temperature\n",
    "        # optionally crop the logits to only the top k options\n",
    "        if top_k is not None:\n",
    "            v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "            logits[logits < v[-1]] = -float('Inf')\n",
    "        # apply softmax to convert logits to (normalized) probabilities\n",
    "        probs = nn.functional.softmax(logits, dim=-1)\n",
    "        # sample from the distribution\n",
    "        idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        # append sampled index to the running sequence and continue\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "    return idx\n",
    "\n",
    "train_loader = utils.get_data(opt, \"train\")\n",
    "\n",
    "# Generate.\n",
    "context = \"\"\"First Citizen:\n",
    "Before we proceed any further, hear me speak. No \"\"\"\n",
    "tokens = torch.Tensor([train_loader.dataset.stoi[x] for x in context]).unsqueeze(0).to(opt.device)\n",
    "generated = generate(model, tokens)\n",
    "print(\"\".join([train_loader.dataset.itos[x.item()] for x in generated]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
